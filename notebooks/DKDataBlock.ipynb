{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368d2cd0",
   "metadata": {},
   "source": [
    "Demonstrating how to get DonkeyCar Tub files into a PyTorch/fastai DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import ColReader, Normalize, RandomSplitter\n",
    "from fastai.metrics import rmse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from donkeycar.parts.tub_v2 import Tub\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malpi.dk.train import preprocessFileList, get_data, get_learner, get_autoencoder, train_autoencoder\n",
    "from malpi.dk.vae import VanillaVAE\n",
    "from malpi.dk.train import get_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ccf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_resnet():\n",
    "    learn2 = cnn_learner(dls, resnet18, loss_func=MSELossFlat(), metrics=[rmse], cbs=ActivationStats(with_hist=True))\n",
    "    learn2.fine_tune(5)\n",
    "    \n",
    "    learn2.recorder.plot_loss()\n",
    "    learn2.show_results(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff9437",
   "metadata": {},
   "source": [
    "The below code is modified from: https://github.com/cmasenas/fastai_navigation_training/blob/master/fastai_train.ipynb.\n",
    "\n",
    "TODO: Figure out how to have multiple output heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15886c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_transform(name, inputs, df_all, batch_tfms, item_tfms, epochs, lr):\n",
    "    dls = get_data(inputs, df_all=df_all, batch_tfms=batch_tfms, item_tfms=item_tfms)\n",
    "    callbacks = [CSVLogger(f\"Transform_{name}.csv\", append=True)]\n",
    "    learn = get_learner(dls)\n",
    "    #learn.no_logging() #Try this to block logging when doing many training test runs\n",
    "    learn.fit_one_cycle(epochs, lr, cbs=callbacks)\n",
    "    #learn.recorder.plot_loss()\n",
    "    #learn.show_results(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d97c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multipel times using a list of Transforms, one at a time.\n",
    "# Compare mean/stdev of best validation loss (or rmse?) for each Transform\n",
    "df_all = get_dataframe(\"track1_warehouse.txt\")\n",
    "transforms = [None]\n",
    "transforms.extend( [*aug_transforms(do_flip=False, size=128)] )\n",
    "for tfm in transforms:\n",
    "    name = \"None\" if tfm is None else str(tfm.__class__.__name__)\n",
    "    print( f\"Transform: {name}\" )\n",
    "    for i in range(5):\n",
    "        print( f\"   Run {i+1}\" )\n",
    "        test_one_transform(name, \"track1_warehouse.txt\", df_all, None, 5, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_learner( learn ):\n",
    "    #dls=nav.dataloaders(df, bs=512)\n",
    "    preds, tgt = learn.get_preds(dl=[dls.one_batch()])\n",
    "\n",
    "    plt.title(\"Target vs Predicted Steering\", fontsize=18, y=1.0)\n",
    "    plt.xlabel(\"Target\", fontsize=14, labelpad=15)\n",
    "    plt.ylabel(\"Predicted\", fontsize=14, labelpad=15)\n",
    "    plt.plot(tgt.T[0], preds.T[0],'bo')\n",
    "    plt.plot([-1,1],[-1,1],'r', linewidth = 4)\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Target vs Predicted Throttle\", fontsize=18, y=1.02)\n",
    "    plt.xlabel(\"Target\", fontsize=14, labelpad=15)\n",
    "    plt.ylabel(\"Predicted\", fontsize=14, labelpad=15)\n",
    "    plt.plot(tgt.T[1], preds.T[1],'bo')\n",
    "    plt.plot([0,1],[0,1],'r', linewidth = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = get_dataframe(\"track1_warehouse.txt\")\n",
    "dls = get_data(\"track1_warehouse.txt\", df_all=df_all, batch_tfms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70395591",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(dls)\n",
    "learn.fit_one_cycle(15, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3873683",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('models/track1_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33765689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_pyplot_memory():\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "df_all = get_dataframe(\"track1_warehouse.txt\")\n",
    "\n",
    "transforms=[None,\n",
    "            RandomResizedCrop(128,p=1.0,min_scale=0.5,ratio=(0.9,1.1)),\n",
    "            RandomErasing(sh=0.2, max_count=6,p=1.0),\n",
    "            Brightness(max_lighting=0.4, p=1.0),\n",
    "            Contrast(max_lighting=0.4, p=1.0),\n",
    "            Saturation(max_lighting=0.4, p=1.0)]\n",
    "#dls = get_data(None, df_all, item_tfms=item_tfms, batch_tfms=batch_tfms)\n",
    "\n",
    "for tfm in transforms:\n",
    "    name = \"None\" if tfm is None else str(tfm.__class__.__name__)\n",
    "    if name == \"RandomResizedCrop\":\n",
    "        item_tfms = tfm\n",
    "        batch_tfms = None\n",
    "    else:\n",
    "        item_tfms = None\n",
    "        batch_tfms = tfm\n",
    "        \n",
    "    dls = get_data(\"track1_warehouse.txt\",\n",
    "                   df_all=df_all,\n",
    "                   item_tfms=item_tfms, batch_tfms=batch_tfms)\n",
    "\n",
    "    dls.show_batch(unique=True, show=True)\n",
    "    plt.savefig( f'Transform_{name}.png' )\n",
    "#clear_pyplot_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bf17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, dls = train_autoencoder( \"tracks_all.txt\", 5, 3e-3, name=\"ae_test1\", verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()\n",
    "learn.show_results(figsize=(20,10))\n",
    "#plt.savefig(name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685477bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "im1 = dls.one_batch()[0]\n",
    "im1_out = learn.model.forward(im1)\n",
    "show_image(im1[idx])\n",
    "show_image(im1_out[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=\"tracks_all.txt\"\n",
    "item_tfms = [Resize(64,method=\"squish\")]\n",
    "dls_1 = get_data(input_file, item_tfms=item_tfms, verbose=True, autoencoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VanillaVAE(128, 64)\n",
    "#learn = Learner(dls_1, vae, loss_func=vae.loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(100, 4.7e-4,\n",
    "                   cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.0, patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae\n",
    "#learn.recorder.plot_loss()\n",
    "#learn.show_results(figsize=(20,10))\n",
    "idx = 2\n",
    "im1 = dls_1.one_batch()[0]\n",
    "im1_out, inp, mu, log_var = learn.model.forward(im1)\n",
    "show_image(im1[idx])\n",
    "show_image(im1_out[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d040e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"vae_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_samp = vae.reparameterize(mu, log_var)\n",
    "img = vae.decode(mu_samp)\n",
    "show_image(img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(\"vae_v2.pkl\", cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75496276",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "input_file=\"tracks_all.txt\"\n",
    "item_tfms = [Resize(128,method=\"squish\")]\n",
    "dls = get_data(input_file, item_tfms=item_tfms, verbose=False, autoencoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31155c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"vae_v3\"\n",
    "input_file=\"tracks_all.txt\"\n",
    "item_tfms = [Resize(128,method=\"squish\")]\n",
    "callbacks = [EarlyStoppingCallback(monitor='valid_loss', min_delta=0.0, patience=5)]\n",
    "epochs = 10\n",
    "lr = 4.7e-4\n",
    "\n",
    "vae = VanillaVAE(128, 64)\n",
    "vae.meta['input'] = input_file\n",
    "vae.meta['image_size'] = (128,128)\n",
    "vae.meta['epochs'] = epochs\n",
    "vae.meta['lr'] = lr\n",
    "\n",
    "dls = get_data(input_file, item_tfms=item_tfms, verbose=False, autoencoder=True)\n",
    "vae.meta['train'] = len(dls.train_ds)\n",
    "vae.meta['valid'] = len(dls.valid_ds)\n",
    "\n",
    "learn = Learner(dls, vae, loss_func=vae.loss_function)\n",
    "learn.fit_one_cycle(epochs, lr, cbs=callbacks)\n",
    "learn.export( name + \".pkl\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=\"tracks_all.txt\"\n",
    "item_tfms = [Resize(128,method=\"squish\")]\n",
    "df_all = get_dataframe(input_file)\n",
    "dls = get_data(input_file, df_all=df_all, item_tfms=item_tfms, verbose=False, autoencoder=False)\n",
    "\n",
    "learn = load_learner(\"models/vae_v3.pkl\", cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ab95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = []\n",
    "var = []\n",
    "outputs = []\n",
    "total = 0\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, controls in dls.train:\n",
    "        total += images.shape[0]\n",
    "        _, _, mu, log_var = learn.forward( images)\n",
    "        mus.append(mu)\n",
    "        var.append(log_var)\n",
    "        outputs.append(controls)\n",
    "        print( f\"Total/len: {total}/{len(outputs)}/{len(mus)}\" )\n",
    "        if total > 200:\n",
    "            break\n",
    "\n",
    "mus = torch.stack(mus)\n",
    "mus = torch.reshape(mus, (mus.shape[0] * mus.shape[1], mus.shape[2])) # combine sub-array and batch dimensions\n",
    "var = torch.stack(var)\n",
    "var = torch.reshape(var, (var.shape[0] * var.shape[1], var.shape[2]))\n",
    "outputs = torch.stack(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38200ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_256 = df_all[['user/angle','user/throttle']][0:256].copy()\n",
    "df_256['mu'] = np.array(mus.cpu()).tolist()\n",
    "df_256['var_log'] = np.array(var.cpu()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4973dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_len = 64\n",
    "blocks = (RegressionBlock(n_out=z_len), RegressionBlock(n_out=z_len), RegressionBlock(n_out=2))\n",
    "y_reader = ColReader(['user/angle','user/throttle'])\n",
    "pascal = DataBlock(blocks=blocks,\n",
    "                   splitter=RandomSplitter(),\n",
    "                   get_x=[ColReader(\"mu\"),ColReader(\"var_log\")],\n",
    "                   get_y=y_reader,\n",
    "                   item_tfms=None,\n",
    "                   batch_tfms=None,\n",
    "                   n_inp=2)\n",
    "\n",
    "dls = pascal.dataloaders(df_256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fdfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DK_PreVAE(nn.Module):\n",
    "    \"\"\" A DonkeyCar driver that takes as inputs mu/log_var from a \n",
    "        pre-trained VAE. \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, outputs=2):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.driver = nn.Sequential(\n",
    "            torch.nn.Linear(self.latent_dim, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(50, outputs),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
    "        # not sure what input will look like. Should be mu and log_var, both of length latent_dim\n",
    "        z = self.reparameterize(input[0], input[1])\n",
    "        return self.driver.forward(z)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
