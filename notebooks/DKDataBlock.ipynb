{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368d2cd0",
   "metadata": {},
   "source": [
    "Demonstrating how to get DonkeyCar Tub files into a PyTorch/fastai DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import ColReader, Normalize, RandomSplitter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from donkeycar.parts.tub_v2 import Tub\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malpi.dk.train import preprocessFileList, get_data, get_learner, get_autoencoder, train_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ccf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_resnet():\n",
    "    learn2 = cnn_learner(dls, resnet18, loss_func=MSELossFlat(), metrics=[rmse], cbs=ActivationStats(with_hist=True))\n",
    "    learn2.fine_tune(5)\n",
    "    \n",
    "    learn2.recorder.plot_loss()\n",
    "    learn2.show_results(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff9437",
   "metadata": {},
   "source": [
    "The below code is modified from: https://github.com/cmasenas/fastai_navigation_training/blob/master/fastai_train.ipynb.\n",
    "\n",
    "TODO: Figure out how to have multiple output heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15886c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_transform(name, inputs, df_all, batch_tfms, item_tfms, epochs, lr):\n",
    "    dls = get_data(inputs, df_all=df_all, batch_tfms=batch_tfms, item_tfms=item_tfms)\n",
    "    callbacks = [CSVLogger(f\"Transform_{name}.csv\", append=True)]\n",
    "    learn = get_learner(dls)\n",
    "    #learn.no_logging() #Try this to block logging when doing many training test runs\n",
    "    learn.fit_one_cycle(epochs, lr, cbs=callbacks)\n",
    "    #learn.recorder.plot_loss()\n",
    "    #learn.show_results(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d97c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multipel times using a list of Transforms, one at a time.\n",
    "# Compare mean/stdev of best validation loss (or rmse?) for each Transform\n",
    "df_all = get_dataframe(\"track1_warehouse.txt\")\n",
    "transforms = [None]\n",
    "transforms.extend( [*aug_transforms(do_flip=False, size=128)] )\n",
    "for tfm in transforms:\n",
    "    name = \"None\" if tfm is None else str(tfm.__class__.__name__)\n",
    "    print( f\"Transform: {name}\" )\n",
    "    for i in range(5):\n",
    "        print( f\"   Run {i+1}\" )\n",
    "        test_one_transform(name, \"track1_warehouse.txt\", df_all, None, 5, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_learner( learn ):\n",
    "    #dls=nav.dataloaders(df, bs=512)\n",
    "    preds, tgt = learn.get_preds(dl=[dls.one_batch()])\n",
    "\n",
    "    plt.title(\"Target vs Predicted Steering\", fontsize=18, y=1.0)\n",
    "    plt.xlabel(\"Target\", fontsize=14, labelpad=15)\n",
    "    plt.ylabel(\"Predicted\", fontsize=14, labelpad=15)\n",
    "    plt.plot(tgt.T[0], preds.T[0],'bo')\n",
    "    plt.plot([-1,1],[-1,1],'r', linewidth = 4)\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Target vs Predicted Throttle\", fontsize=18, y=1.02)\n",
    "    plt.xlabel(\"Target\", fontsize=14, labelpad=15)\n",
    "    plt.ylabel(\"Predicted\", fontsize=14, labelpad=15)\n",
    "    plt.plot(tgt.T[1], preds.T[1],'bo')\n",
    "    plt.plot([0,1],[0,1],'r', linewidth = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = get_dataframe(\"track1_warehouse.txt\")\n",
    "dls = get_data(\"track1_warehouse.txt\", df_all=df_all, batch_tfms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70395591",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(dls)\n",
    "learn.fit_one_cycle(15, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3873683",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('models/track1_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33765689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_pyplot_memory():\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "df_all = get_dataframe(\"track1_warehouse.txt\")\n",
    "\n",
    "transforms=[None,\n",
    "            RandomResizedCrop(128,p=1.0,min_scale=0.5,ratio=(0.9,1.1)),\n",
    "            RandomErasing(sh=0.2, max_count=6,p=1.0),\n",
    "            Brightness(max_lighting=0.4, p=1.0),\n",
    "            Contrast(max_lighting=0.4, p=1.0),\n",
    "            Saturation(max_lighting=0.4, p=1.0)]\n",
    "#dls = get_data(None, df_all, item_tfms=item_tfms, batch_tfms=batch_tfms)\n",
    "\n",
    "for tfm in transforms:\n",
    "    name = \"None\" if tfm is None else str(tfm.__class__.__name__)\n",
    "    if name == \"RandomResizedCrop\":\n",
    "        item_tfms = tfm\n",
    "        batch_tfms = None\n",
    "    else:\n",
    "        item_tfms = None\n",
    "        batch_tfms = tfm\n",
    "        \n",
    "    dls = get_data(\"track1_warehouse.txt\",\n",
    "                   df_all=df_all,\n",
    "                   item_tfms=item_tfms, batch_tfms=batch_tfms)\n",
    "\n",
    "    dls.show_batch(unique=True, show=True)\n",
    "    plt.savefig( f'Transform_{name}.png' )\n",
    "#clear_pyplot_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, dls = train_autoencoder( \"tracks_all.txt\", 5, 3e-3, name=\"ae_test1\", verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()\n",
    "learn.show_results(figsize=(20,10))\n",
    "#plt.savefig(name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "im1 = dls.one_batch()[0]\n",
    "im1_out = learn.model.forward(im1)\n",
    "show_image(im1[idx])\n",
    "show_image(im1_out[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422cbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
